{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minería De Datos #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1\n",
    "* Utilice los siguientes métodos para normalizar el siguiente conjunto de datos<br/>\n",
    "$$200; 300; 400; 600; 1000$$\n",
    "   1. Normalización min-max fijando mín = 0 y máx = 1\n",
    "   2. Normalización Z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución 1**\n",
    "$$v^{'}=\\frac{v-min_A}{max_A-min_A}(new \\_max_A-new\\_min_A)+new\\_min_A$$\n",
    "$max_A=1000$<br/>\n",
    "$min_A=200$<br/>\n",
    "$new\\_max_A=1$<br/>\n",
    "$new\\_min_A=0$<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.    0.125 0.25  0.5   1.   ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([200,300,400,600,1000])\n",
    "max_A = X.max()\n",
    "min_A = X.min()\n",
    "new_max_A = np.array([1])\n",
    "new_min_A = np.array([0])\n",
    "new_X = ((X-min_A)/(max_A-min_A))*(new_max_A-new_min_A)+new_min_A\n",
    "print(new_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución 2**\n",
    "$$v^{'}=\\frac{v-mean_A}{desv_A}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.06066017 -0.70710678 -0.35355339  0.35355339  1.76776695]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([200,300,400,600,1000])\n",
    "mean_A = X.mean()\n",
    "desv_A = X.std()\n",
    "new_X = ((X-mean_A)/desv_A)\n",
    "print(new_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 2\n",
    "* Encuentre la solución de una regresión ridge para un valor genérico $\\lambda$ y para el modelo lineal <br/><br/>\n",
    "$$y=\\beta_0+\\beta_1 X +\\epsilon$$<br/>\n",
    "Muestre que para $\\lambda=0.4$ la solución de la regresión ridge es $\\hat{y}=40+1.75X$.<br/><br/>\n",
    "Datos $X^{T}=(-2,-1,-1,-1, 0, 1, 2, 2)^{T}$; $y^{T}=(35, 40, 36, 38, 40, 43, 45, 43)^{T}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución**\n",
    "$$\\hat{\\beta}^{ridge} = (X^T X + \\lambda I)^{-1}X^Ty$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "X = np.array([-2,-1,-1,-1, 0, 1, 2, 2])\n",
    "y = np.array([35, 40, 36, 38, 40, 43, 45, 43])\n",
    "plt.scatter(x, y, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.13414634]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x1 = np.array([-2,-1,-1,-1, 0, 1, 2, 2])\n",
    "#x1 = (x1-x1.mean())\n",
    "#/x1.std()\n",
    "X = np.matrix(x1).transpose()\n",
    "y = np.matrix([35, 40, 36, 38, 40, 43, 45, 43]).transpose()\n",
    "\n",
    "from numpy.linalg import inv\n",
    "beta_ridge_0 = y.mean()\n",
    "beta_ridge = inv(X.transpose()*X + 0.4*np.identity(1))*(X.transpose()*y)\n",
    "print(beta_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38.0952381   2.13414634]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "clf = Ridge(alpha=0.4,fit_intercept=False)\n",
    "a=clf.fit(X, y) \n",
    "print(a.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 3\n",
    "* Demuestre que la regresión RIDGE es equivalente al siguiente problema de optimización\n",
    "$$\\hat{\\beta}^c = \\arg min{\\sum_{i=1}^N [y_i - \\beta_0^c - \\sum_{j=1}^p(x_{i,j}-\\bar{x}_j)\\beta_j^c]^2+\\lambda \\sum_{j=1}^p(\\beta_j^c)^2}$$\n",
    "Encuentre la solución $\\hat{\\beta}^c$ y comparela con la solución original de la regresión ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 5\n",
    "* Implemente el método del gradiente proximal para el problema LASSO. Utilice esta implementación para encontrar los dos factores físico-quimicos más importantes para la calidad del vino portugues [Vinho Verde](http://archive.ics.uci.edu/ml/datasets/Wine+Quality).<br/>\n",
    "Nota: Para el criterio de parada utilice el número de iteraciones (e.g. 1000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algortimo LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $\\beta$ aleatorio\n",
    "2. $\\tau$>0\n",
    "3. $\\beta^{i+1} = \\displaystyle {prox_{\\tau \\delta f}^{}} \\left( \\beta^i +2\\tau X^T(y-X\\beta^i) \\right) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución**\n",
    "\n",
    "Dado $f(\\beta) = \\lambda ||\\beta||_1$, tenemos que : $$prox_{\\tau \\delta f}(\\beta)$$ puede ser expresado como:\n",
    "$$max(0,\\beta-\\lambda \\tau)-max(0,-(\\beta+\\lambda \\tau));$$\n",
    "Ahora tomamos $\\beta=\\beta^i +2\\tau X^T(y-X\\beta^i)$ y realizamos 1000 iteraciones del método."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función Proximal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_l1(beta, plambda):\n",
    "    vect = np.array(beta)-plambda\n",
    "    vect2 = -np.array(beta)-plambda\n",
    "    a = np.zeros((n,1))\n",
    "    z = np.max(np.concatenate((a, vect),axis=1), axis=1) - np.max(np.concatenate((a, vect2),axis=1), axis=1)\n",
    "    return np.matrix(z).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de Costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_cost(y,X,beta,plambda):\n",
    "    vect = np.array(y)-np.array(X*beta)\n",
    "    return np.linalg.norm(y-X*beta, ord=2)**2 + plambda * np.linalg.norm(beta, ord=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parámetros de Entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Python'"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"C:\\Python\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 1)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Los datos de entrada deben estar en el direcotrio local\n",
    "\n",
    "df = pd.read_csv('winequality-red.csv',sep=\";\")\n",
    "X_train = np.matrix(df.iloc[:,0:11])\n",
    "y_train = np.matrix(df.iloc[:,11:12])\n",
    "y_train.shape\n",
    "#x_test = Array(d[\"x_test\"]);\n",
    "#y_test = Array(d[\"y_test\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parámetros\n",
    "\n",
    "beta = np.matrix(np.zeros(11)).transpose()\n",
    "tau = 0.0002\n",
    "plambda = 0.01\n",
    "gamma = 0.5\n",
    "maxiter = 10000\n",
    "tol = 1e-3\n",
    "res = 1\n",
    "it = 0\n",
    "costos = np.array([0])\n",
    "beta_prev = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduardo\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n"
     ]
    }
   ],
   "source": [
    "for i in range(maxiter):\n",
    "    it =it+1\n",
    "    grad_g = np.array(-2*X_train.transpose()*(y_train-X_train*beta))\n",
    "    z = prox_l1(beta + tau*grad_g , tau*plambda)\n",
    "    cost = lasso_cost(y_train,X_train,z,plambda)\n",
    "    beta_prev = beta\n",
    "    beta = z\n",
    "    #costos = np.concatenate((costos, cost),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
